{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "%load_ext autoreload\n",
                "%autoreload 2\n",
                "\n",
                "import torch\n",
                "import matplotlib.pyplot as plt\n",
                "import numpy as np\n",
                "import yaml\n",
                "import imageio.v3 as iio\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "config_file = './configs/lego.yaml'\n",
                "with open(config_file, 'r') as file:\n",
                "    config = yaml.safe_load(file)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "from utils.Renderer import Renderer\n",
                "\n",
                "renderer = Renderer(config['renderer'])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [],
            "source": [
                "from utils.DataLoaderBlender import DataLoaderBlender\n",
                "\n",
                "data_loader = DataLoaderBlender(config['data'])\n",
                "\n",
                "poses, focal, H, W = data_loader.getDataset('test', exclude_imgs=True)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {
                "scrolled": true
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "cuda\n",
                        "9\n",
                        "9\n",
                        "epoch\n",
                        "model_fine_state_dict\n",
                        "model_sparse_state_dict\n",
                        "optimizer_state_dict\n",
                        "train_loss_history\n",
                        "90\n"
                    ]
                }
            ],
            "source": [
                "from models.Nerf import Nerf\n",
                "from utils.Inference import Inference\n",
                "import yaml\n",
                "device =  'cuda' if torch.cuda.is_available() else 'cpu'\n",
                "# device = 'cpu'\n",
                "print(device)\n",
                "model_sparse = Nerf(config['model']['L_xyz'],config['model']['L_dir'])\n",
                "model_sparse.to(device)\n",
                "model_fine = Nerf(config['model']['L_xyz'],config['model']['L_dir'])\n",
                "model_fine.to(device)\n",
                "models = (model_sparse, model_fine)\n",
                "inference = Inference(models=models, \n",
                "                    checkpoint_path=\"nerf_lego_pt3d28072023234920.pt\", \n",
                "                    device=device, renderer=renderer, dir_path=config['inference']['inference_folder'])\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [],
            "source": [
                "device = 'cpu'\n",
                "if torch.cuda.is_available():\n",
                "    device = torch.cuda.current_device()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [],
            "source": [
                "from utils.Camera import Camera\n",
                "\n",
                "cameras = []\n",
                "# H, W = images[0].shape[:2]\n",
                "\n",
                "for i in range(poses.shape[0]):\n",
                "    cameras.append(Camera(H, W, poses[i], focal, device))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "torch.Size([800, 800, 3]) torch.Size([800, 800, 3])\n",
                        "r_000.png\n",
                        "torch.Size([800, 800, 3]) torch.Size([800, 800, 3])\n",
                        "r_002.png\n",
                        "torch.Size([800, 800, 3]) torch.Size([800, 800, 3])\n",
                        "r_004.png\n",
                        "torch.Size([800, 800, 3]) torch.Size([800, 800, 3])\n",
                        "r_006.png\n",
                        "torch.Size([800, 800, 3]) torch.Size([800, 800, 3])\n",
                        "r_008.png\n",
                        "torch.Size([800, 800, 3]) torch.Size([800, 800, 3])\n",
                        "r_010.png\n",
                        "torch.Size([800, 800, 3]) torch.Size([800, 800, 3])\n",
                        "r_012.png\n",
                        "torch.Size([800, 800, 3]) torch.Size([800, 800, 3])\n",
                        "r_014.png\n",
                        "torch.Size([800, 800, 3]) torch.Size([800, 800, 3])\n",
                        "r_016.png\n",
                        "torch.Size([800, 800, 3]) torch.Size([800, 800, 3])\n",
                        "r_018.png\n",
                        "torch.Size([800, 800, 3]) torch.Size([800, 800, 3])\n",
                        "r_020.png\n",
                        "torch.Size([800, 800, 3]) torch.Size([800, 800, 3])\n",
                        "r_022.png\n",
                        "torch.Size([800, 800, 3]) torch.Size([800, 800, 3])\n",
                        "r_024.png\n",
                        "torch.Size([800, 800, 3]) torch.Size([800, 800, 3])\n",
                        "r_026.png\n",
                        "torch.Size([800, 800, 3]) torch.Size([800, 800, 3])\n",
                        "r_028.png\n",
                        "torch.Size([800, 800, 3]) torch.Size([800, 800, 3])\n",
                        "r_030.png\n",
                        "torch.Size([800, 800, 3]) torch.Size([800, 800, 3])\n",
                        "r_032.png\n",
                        "torch.Size([800, 800, 3]) torch.Size([800, 800, 3])\n",
                        "r_034.png\n",
                        "torch.Size([800, 800, 3]) torch.Size([800, 800, 3])\n",
                        "r_036.png\n",
                        "torch.Size([800, 800, 3]) torch.Size([800, 800, 3])\n",
                        "r_038.png\n",
                        "torch.Size([800, 800, 3]) torch.Size([800, 800, 3])\n",
                        "r_040.png\n",
                        "torch.Size([800, 800, 3]) torch.Size([800, 800, 3])\n",
                        "r_042.png\n",
                        "torch.Size([800, 800, 3]) torch.Size([800, 800, 3])\n",
                        "r_044.png\n",
                        "torch.Size([800, 800, 3]) torch.Size([800, 800, 3])\n",
                        "r_046.png\n",
                        "torch.Size([800, 800, 3]) torch.Size([800, 800, 3])\n",
                        "r_048.png\n",
                        "torch.Size([800, 800, 3]) torch.Size([800, 800, 3])\n",
                        "r_050.png\n",
                        "torch.Size([800, 800, 3]) torch.Size([800, 800, 3])\n",
                        "r_052.png\n",
                        "torch.Size([800, 800, 3]) torch.Size([800, 800, 3])\n",
                        "r_054.png\n",
                        "torch.Size([800, 800, 3]) torch.Size([800, 800, 3])\n",
                        "r_056.png\n",
                        "torch.Size([800, 800, 3]) torch.Size([800, 800, 3])\n",
                        "r_058.png\n",
                        "torch.Size([800, 800, 3]) torch.Size([800, 800, 3])\n",
                        "r_060.png\n",
                        "torch.Size([800, 800, 3]) torch.Size([800, 800, 3])\n",
                        "r_062.png\n",
                        "torch.Size([800, 800, 3]) torch.Size([800, 800, 3])\n",
                        "r_064.png\n",
                        "torch.Size([800, 800, 3]) torch.Size([800, 800, 3])\n",
                        "r_066.png\n",
                        "torch.Size([800, 800, 3]) torch.Size([800, 800, 3])\n",
                        "r_068.png\n",
                        "torch.Size([800, 800, 3]) torch.Size([800, 800, 3])\n",
                        "r_070.png\n",
                        "torch.Size([800, 800, 3]) torch.Size([800, 800, 3])\n",
                        "r_072.png\n",
                        "torch.Size([800, 800, 3]) torch.Size([800, 800, 3])\n",
                        "r_074.png\n",
                        "torch.Size([800, 800, 3]) torch.Size([800, 800, 3])\n",
                        "r_076.png\n",
                        "torch.Size([800, 800, 3]) torch.Size([800, 800, 3])\n",
                        "r_078.png\n",
                        "torch.Size([800, 800, 3]) torch.Size([800, 800, 3])\n",
                        "r_080.png\n",
                        "torch.Size([800, 800, 3]) torch.Size([800, 800, 3])\n",
                        "r_082.png\n",
                        "torch.Size([800, 800, 3]) torch.Size([800, 800, 3])\n",
                        "r_084.png\n",
                        "torch.Size([800, 800, 3]) torch.Size([800, 800, 3])\n",
                        "r_086.png\n",
                        "torch.Size([800, 800, 3]) torch.Size([800, 800, 3])\n",
                        "r_088.png\n",
                        "torch.Size([800, 800, 3]) torch.Size([800, 800, 3])\n",
                        "r_090.png\n",
                        "torch.Size([800, 800, 3]) torch.Size([800, 800, 3])\n"
                    ]
                }
            ],
            "source": [
                "for i in range(0, len(cameras), config['inference']['step']):\n",
                "    file_name = f'r_{i:03d}.png'\n",
                "    inference.eval_and_save(cameras[i], file_name)\n",
                "    print(file_name)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.10"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}